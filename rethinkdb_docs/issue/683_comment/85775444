IssueComment
  { issueCommentUpdatedAt = 2015 (-03) (-25) 01 : 48 : 11 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 17789
        , simpleUserLogin = N "gchpaco"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/17789?v=3"
        , simpleUserUrl = "https://api.github.com/users/gchpaco"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/docs/issues/comments/85775444"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/docs/issues/683#issuecomment-85775444"
  , issueCommentCreatedAt = 2015 (-03) (-25) 01 : 37 : 01 UTC
  , issueCommentBody =
      "# Accessing RethinkDB using Tornado\r\n\r\nNew in 2.0 is integration with the [Tornado web framework](http://www.tornadoweb.org).  This permits users to recieve updates from several requests asynchronously, and is particularly useful for multiple changefeeds.\r\n\r\n## Basic Usage\r\n\r\nThe first task is to tell the driver which event loop you are using.  We intend to support multiple event loops in time, although presently we only support Tornado.  This is done through the `r.set_loop_type` call, as follows:\r\n\r\n```python\r\nimport rethinkdb as r\r\nfrom tornado import ioloop, gen\r\nfrom tornado.concurrent import Future, chain_future\r\nimport functools\r\n\r\nr.set_loop_type(\"tornado\")\r\n```\r\n\r\nAfter this, `r.connect` will return a Tornado `Future`, as will `r.run`.  We have designed the API assuming you will prefer to use Tornado's coroutine support.\r\n\r\nA simple skeleton framework for testing is as follows:\r\n\r\n```python\r\n@gen.coroutine\r\ndef run_coro(coroutine, *args, **kwargs):\r\n    conn = yield r.connect(host=\"...\")\r\n    yield coroutine(conn, *args, **kwargs)\r\n    yield conn.close()\r\n\r\nif __name__ == \"__main__\":\r\n    ioloop.IOLoop.instance().run_sync(functools.partial(run_coro, example_coroutine))\r\n```\r\n\r\n### Example 1: simple use\r\n\r\n```python\r\n@gen.coroutine\r\ndef single_row(connection):\r\n    # Insert some data.\r\n    yield r.table('test').insert([{\"id\": 0}, {\"id\": 1}, {\"id\": 2}]).run(connection)\r\n    # Print the first row in the table.\r\n    row = yield r.table('test').get(0).run(connection)\r\n    print(row)\r\n```\r\n\r\nWill print:\r\n\r\n```python\r\n{u'id': 0}\r\n```\r\n\r\n### Example 2: using a cursor\r\n\r\n```python\r\n@gen.coroutine\r\ndef use_cursor(connection):\r\n    # Insert some data.\r\n    yield r.table('test').insert([{\"id\": 0}, {\"id\": 1}, {\"id\": 2}]).run(connection)\r\n    # Print every row in the table.\r\n    for future in (yield r.table('test').order_by(index='id').run(connection)):\r\n        item = yield future\r\n        print(item)\r\n```\r\n\r\nWill print:\r\n\r\n```python\r\n{u'id': 0}\r\n{u'id': 1}\r\n{u'id': 2}\r\n```\r\n\r\n## Basic Error Handling\r\n\r\nIf there is an error during an asynchronous operation, the relevant `yield` statement will throw an exception as normal.  This can happen immediately (for example, you might reference a table that doesn't exist) or you might get large amounts of data before the error (for example, your network might be disrupted after the connection is established).\r\n\r\nOne error in particular is notable.  If you have a coroutine set to consume a changefeed indefinitely, and the connection closes, the coroutine will experience a `RqlRuntimeError`.\r\n\r\n### Example 1: re-thrown errors\r\n\r\n```python\r\n@gen.coroutine\r\ndef bad_table(connection):\r\n    yield r.table('non_existent').run(connection)\r\n```\r\n\r\nWill produce an error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n... elided ...\r\nrethinkdb.errors.RqlRuntimeError: Table `test.non_existent` does not exist. in:\r\nr.table('non_existent')\r\n^^^^^^^^^^^^^^^^^^^^^^^\r\n```\r\n\r\n### Example 2: catching errors in the coroutine\r\n\r\n```python\r\n@gen.coroutine\r\ndef catch_bad_table(connection):\r\n    try:\r\n        yield r.table('non_existent').run(connection)\r\n    except r.RqlRuntimeError:\r\n        print(\"Saw error\")\r\n```\r\n\r\nWill print:\r\n\r\n```\r\nSaw error\r\n```\r\n\r\n## Controlling coroutine execution\r\n\r\nYou may wish for one part of your code run in the background; two frequent requests that go along with this are to wait until the background code is ready, and to cancel the background code.  All these constructions are useful in changefeeds, which we will discuss below.\r\n\r\n### Running a coroutine in the background\r\n\r\nStarting a background coroutine can be done with the `add_callback` or `add_future` method on Tornado's `IOLoop`.  Similarly useful, albeit a bit more specialized, are `call_at`, `call_later`, and `spawn_callback`.  An example with `add_callback` might look like this:\r\n\r\n```python\r\n@gen.coroutine\r\ndef background_task():\r\n    print(\"In background task\")\r\n    yield gen.sleep(0.5)\r\n    print(\"Done with background task\")\r\n@gen.coroutine\r\ndef spawn_background_task(connection):\r\n    loop = ioloop.IOLoop.current()\r\n    loop.add_callback(background_task)\r\n    yield gen.sleep(1.0)\r\n    print(\"Done with foreground task\")\r\n```\r\n\r\nWhich will print:\r\n\r\n```\r\nIn background task\r\nDone with background task\r\nDone with foreground task\r\n```\r\n\r\n### Waiting until a coroutine is ready\r\n\r\nThe `gen.sleep` in the previous example is unsatisfying and potentially buggy.  We can do better with a `Future`.\r\n\r\n```python\r\n@gen.coroutine\r\ndef notifying_background_task(notification):\r\n    print(\"In background task\")\r\n    notification.set_result(True)\r\n    yield gen.sleep(0.5)\r\n    print(\"Done with background task\")\r\n\r\n@gen.coroutine\r\ndef spawn_notifying_background_task(connection):\r\n    notification = Future()\r\n    loop = ioloop.IOLoop.current()\r\n    loop.add_callback(notifying_background_task, notification)\r\n    print(\"Callback added\")\r\n    yield notification\r\n    print(\"Callback begun work\")\r\n    yield gen.sleep(1.0)\r\n    print(\"Done with foreground task\")\r\n```\r\n\r\nNow we get:\r\n\r\n```\r\nCallback added\r\nIn background task\r\nCallback begun work\r\nDone with background task\r\nDone with foreground task\r\n```\r\n\r\n### Cancelling background coroutines\r\n\r\nWe aren't quite ready for production yet; we would like to be able to cancel the background task.  This is done through Tornado's `chain_future` function, and looks like this:\r\n\r\n```python\r\n@gen.coroutine\r\ndef cancelling_background_task(ready, cancel, sentinel):\r\n    print(\"In background task\")\r\n    ready.set_result(True)\r\n    future = gen.sleep(0.5)\r\n    chain_future(cancel, future)\r\n    result = yield future\r\n    if result is sentinel:\r\n        print(\"Background task was cancelled\")\r\n        raise gen.Return(False)\r\n    else:\r\n        print(\"Background task slept normally\")\r\n        raise gen.Return(True)\r\n\r\n@gen.coroutine\r\ndef spawn_cancelling_background_task(connection, delay):\r\n    sentinel = object()\r\n    ready = Future()\r\n    cancel = Future()\r\n    background = cancelling_background_task(ready, cancel, sentinel)\r\n    print(\"Callback added\")\r\n    yield ready\r\n    print(\"Callback begun work\")\r\n    yield gen.sleep(delay)\r\n    print(\"Done with foreground task\")\r\n    cancel.set_result(sentinel)\r\n    yield background\r\n    print(\"Done with everything\")\r\n```\r\n\r\nThe `sentinel` object here is so that `cancelling_background_task` can tell the difference between being woken up from sleep and being woken up by being cancelled.  We don't actually need to advertise the `cancelling_background_task` to Tornado this time, and we'd like to be sure that it finishes; otherwise we could use `add_callback` as before.\r\n\r\nWhen run with a delay of 0.9 in the foreground task, meaning that the background task will wake from sleep normally rather than be cancelled, we see:\r\n\r\n```\r\nIn background task\r\nCallback added\r\nCallback begun work\r\nBackground task slept normally\r\nDone with foreground task\r\nDone with everything\r\n```\r\n\r\nWhen run with a delay of 0.2, ensuring the background task is cancelled, we see instead:\r\n\r\n```\r\nIn background task\r\nCallback added\r\nCallback begun work\r\nDone with foreground task\r\nBackground task was cancelled\r\nDone with everything\r\n```\r\n\r\n## Subscribing to changefeeds\r\n\r\nChangefeeds can be used like normal streams, but we anticipate one of the most common uses for the asynchronous database API is for handling multiple change feeds.  This is possible by scheduling background coroutines as seen in the previous section.  As an example, consider this changefeed handler:\r\n\r\n```python\r\n@gen.coroutine\r\ndef print_cfeed_data(connection, table):\r\n    feed = yield r.table(table).changes().run(connection)\r\n    for cursor in feed:\r\n        item = yield cursor\r\n        print(item)\r\n```\r\n\r\nWe can schedule it on the tornado IO loop with this code:\r\n\r\n```python\r\nioloop.IOLoop.current().add_callback(print_cfeed_data, connection, table)\r\n```\r\n\r\nAfter which point it will run in the background, printing out changes.  We can then alter the table, and the changes will be noticed.\r\n\r\nA larger example here is in order.  Consider this setup:\r\n\r\n```python\r\nclass BuggyChangefeedNoticer(object):\r\n    def __init__(self, connection):\r\n        self._connection = connection\r\n    @gen.coroutine\r\n    def print_cfeed_data(self, table):\r\n        feed = yield r.table(table).changes().run(self._connection)\r\n        try:\r\n            for cursor in feed:\r\n                item = yield cursor\r\n                print(\"Seen on table %s: %s\" % (table, item))\r\n        except r.RqlRuntimeError as e:\r\n            # termination of connection\r\n            print(\"Saw error\", e)\r\n    @gen.coroutine\r\n    def table_write(self, table):\r\n        for i in range(10):\r\n            yield r.table(table).insert({'id': i}).run(self._connection)\r\n    @gen.coroutine\r\n    def exercise_changefeeds(self):\r\n        loop = ioloop.IOLoop.current()\r\n        loop.add_callback(self.print_cfeed_data, 'a')\r\n        loop.add_callback(self.print_cfeed_data, 'b')\r\n        yield [self.table_write('a'), self.table_write('b')]\r\n    @classmethod\r\n    @gen.coroutine\r\n    def run(cls, connection):\r\n        if 'a' in (yield r.table_list().run(connection)):\r\n            yield r.table_drop('a').run(connection)\r\n        yield r.table_create('a').run(connection)\r\n        if 'b' in (yield r.table_list().run(connection)):\r\n            yield r.table_drop('b').run(connection)\r\n        yield r.table_create('b').run(connection)\r\n        noticer = cls(connection)\r\n        yield noticer.exercise_changefeeds()\r\n```\r\n\r\nThis code contains a subtle bug, which we can observe looking at the output:\r\n\r\n```\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 1}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 2}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 3}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 4}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 5}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 3}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 4}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 6}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 5}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 7}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 6}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 8}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 7}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 9}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 8}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 9}}\r\nSaw error Connection is closed. in:\r\nr.table('a').changes()\r\n^^^^^^^^^^^^^^^^^^^^^^\r\nSaw error Connection is closed. in:\r\nr.table('b').changes()\r\n^^^^^^^^^^^^^^^^^^^^^^\r\n```\r\n\r\nThere's the alarming exception at the end, but also note that we missed the insertion of `0` in both tables, and some other values in table `b`, too; the first one we saw there was `3`.  This is because our changefeeds may not get initialized before the write starts.  We also never cancel the changefeeds set up by `self.print_cfeed_data`, which is why the exception is thrown when the database connection is closed.  Fixing both these issues is relatively straightforward:\r\n\r\n```python\r\nclass FixedChangefeedNoticer(object):\r\n    def __init__(self, connection):\r\n        self._connection = connection\r\n        self._sentinel = object()\r\n        self._cancel_future = Future()\r\n    @gen.coroutine\r\n    def print_cfeed_data(self, table):\r\n        feed = yield r.table(table).changes().run(self._connection)\r\n        self._feeds_ready[table].set_result(True)\r\n        for cursor in feed:\r\n            chain_future(self._cancel_future, cursor)\r\n            item = yield cursor\r\n            if item is self._sentinel:\r\n                return\r\n            print(\"Seen on table %s: %s\" % (table, item))\r\n    @gen.coroutine\r\n    def table_write(self, table):\r\n        for i in range(10):\r\n            yield r.table(table).insert({'id': i}).run(self._connection)\r\n    @gen.coroutine\r\n    def exercise_changefeeds(self):\r\n        self._feeds_ready = {'a': Future(), 'b': Future()}\r\n        loop = ioloop.IOLoop.current()\r\n        loop.add_callback(self.print_cfeed_data, 'a')\r\n        loop.add_callback(self.print_cfeed_data, 'b')\r\n        yield self._feeds_ready\r\n        yield [self.table_write('a'), self.table_write('b')]\r\n        self._cancel_future.set_result(self._sentinel)\r\n    @classmethod\r\n    @gen.coroutine\r\n    def run(cls, connection):\r\n        if 'a' in (yield r.table_list().run(connection)):\r\n            yield r.table_drop('a').run(connection)\r\n        yield r.table_create('a').run(connection)\r\n        if 'b' in (yield r.table_list().run(connection)):\r\n            yield r.table_drop('b').run(connection)\r\n        yield r.table_create('b').run(connection)\r\n        noticer = cls(connection)\r\n        yield noticer.exercise_changefeeds()\r\n```\r\n\r\nNow we see this output:\r\n\r\n```\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 0}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 0}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 1}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 1}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 2}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 2}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 3}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 3}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 4}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 4}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 5}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 6}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 5}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 7}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 6}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 8}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 7}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 9}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 8}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 9}}\r\n```\r\n"
  , issueCommentId = 85775444
  }