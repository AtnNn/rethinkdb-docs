IssueComment
  { issueCommentUpdatedAt = 2015 (-09) (-22) 03 : 28 : 17 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 552910
        , simpleUserLogin = N "Tryneus"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/552910?v=3"
        , simpleUserUrl = "https://api.github.com/users/Tryneus"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/docs/issues/comments/142169993"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/docs/issues/831#issuecomment-142169993"
  , issueCommentCreatedAt = 2015 (-09) (-22) 03 : 28 : 17 UTC
  , issueCommentBody =
      "I used the existing Tornado examples as a starting point.  I skipped the sections on running tasks in the background and canceling background tasks because these are just generic Tornado/Twisted usage, and we probably shouldn't be telling users how to do this.  In addition, the Tornado section seems to end quite abruptly, so I added a bit more after the final example.\r\n\r\n### Basic Usage\r\nThe `set_loop_type` command should be used before `connect` to set the RethinkDB Python driver to use asynchronous event loops.  This should be set to `'twisted'` to use a `Connection` compatible with the Twisted reactor.\r\n \r\n```py\r\nimport rethinkdb as r\r\nfrom twisted.internet import reactor, defer\r\nfrom twisted.internet.defer import inlineCallbacks, returnValue\r\n\r\nr.set_loop_type('twisted')\r\nconnection = r.connect(host='localhost', port=28015)\r\n```\r\n\r\nAfter executing `set_loop_type`, `r.connect` will return a Tornado `Deferred`, as will `r.run`.\r\n\r\n**Example:** Simple use\r\n\r\n```py\r\n@inlineCallbacks\r\ndef single_row(conn_deferred):\r\n    # Wait for the connection to be ready\r\n    conn = yield conn_deferred\r\n    # Insert some data\r\n    yield r.table('test').insert([{\"id\": 0}, {\"id\": 1}, {\"id\": 2}]).run(conn)\r\n    # Print the first row in the table\r\n    row = yield r.table('test').get(0).run(conn)\r\n    print(row)\r\n\r\n# Output\r\n{u'id': 0}\r\n```\r\n\r\n**Example:** Using a cursor\r\n\r\n```py\r\n@inlineCallbacks\r\ndef use_cursor(conn):\r\n    # Insert some data\r\n    yield r.table('test').insert([{\"id\": 0}, {\"id\": 1}, {\"id\": 2}]).run(conn)\r\n    # Print every row in the table.\r\n    cursor = yield r.table('test').order_by(index=\"id\").run(conn)\r\n    while (yield cursor.fetch_next()):\r\n        item = yield cursor.next()\r\n        print(item)\r\n\r\n# Output:\r\n{u'id': 0}\r\n{u'id': 1}\r\n{u'id': 2}\r\n```\r\n\r\nNote that looping over a cursor must be done with `while` and `fetch_next`, rather than using a `for x in cursor` loop.\r\n\r\n### Error handling\r\n\r\nIf an error occurs during an asynchronous operation, the `yield` statement will throw an exception as normal. This may happen immediately (for example, you might reference a table that doesn\8217t exist), but your application might receive large amounts of data before the error (for example, your network might be disrupted after the connection is established).\r\n\r\nOne error in particular is notable. If you have a task that consume a changefeed indefinitely, and the connection closes, the task will experience a `ReqlRuntimeError`.\r\n\r\n**Example:** Re-thrown errors\r\n\r\n```py\r\n@inlineCallbacks\r\ndef bad_table(conn):\r\n    yield r.table('non_existent').run(conn)\r\n\r\nUnhandled error in Deferred:\r\nTraceback (most recent call last):\r\nFailure: rethinkdb.errors.ReqlOpFailedError: Table `test.non_existent` does not exist in:\r\nr.table('non_existent')\r\n^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n```\r\n\r\n**Example:** Catching runtime errors\r\n\r\n```py\r\n@inlineCallbacks\r\ndef catch_bad_table(conn):\r\n    try:\r\n        yield r.table('non_existent').run(conn)\r\n    except r.ReqlRuntimeError:\r\n        print(\"Saw error\")\r\n\r\n# Output\r\nSaw error\r\n```\r\n\r\n### Subscribing to changefeeds\r\n\r\nThe asynchronous database API allows you to handle multiple changefeeds simultaneously by running multiple background tasks.  As an example, consider this changefeed handler:\r\n\r\n```py\r\n@inlineCallbacks\r\ndef print_feed(conn, table):\r\n    feed = yield r.table(table).changes().run(conn)\r\n    while (yield feed.fetch_next()):\r\n        item = yield feed.next()\r\n        print(\"Seen on table %s: %s\" % (table, str(item)))\r\n```\r\n\r\nWe can schedule it on the Twisted `reactor` with this code:\r\n```py\r\nreactor.callLater(0, print_cfeed_data, conn, table)\r\n```\r\n\r\nNow the task will run in the background, printing out changes.  When we alter the table, the changes will be noticed.\r\n\r\nNow consider a larger example:\r\n\r\n```py\r\n@inlineCallbacks\r\ndef print_feed(conn, table, ready, cancel):\r\n    def errback_feed(feed, err):\r\n        feed.close()\r\n        return err\r\n\r\n    feed = yield r.table(table).changes().run(conn)\r\n    cancel.addErrback(lambda err: errback_feed(feed, err))\r\n    ready.callback(None)\r\n    while (yield feed.fetch_next()):\r\n        item = yield feed.next()\r\n        print(\"Seen on table %s: %s\" % (table, str(item)))\r\n\r\n@inlineCallbacks\r\ndef table_write(conn, table):\r\n    for i in range(10):\r\n        yield r.table(table).insert({'id': i}).run(conn)\r\n\r\n@inlineCallbacks\r\ndef notice_changes(conn, *tables):\r\n    # Reset the state of the tables on the server\r\n    if len(tables) > 0:\r\n        table_list = yield r.table_list().run(conn)\r\n        yield defer.DeferredList([r.table_drop(t).run(conn) for t in tables if t in table_list])\r\n    yield defer.DeferredList([r.table_create(t).run(conn) for t in tables])\r\n\r\n    readies = [defer.Deferred() for t in tables]\r\n    cancel = defer.Deferred()\r\n    feeds = [print_feed(conn, table, ready, cancel) for table, ready in zip(tables, readies)]\r\n\r\n    # Wait for the feeds to become ready\r\n    yield defer.gatherResults(readies)\r\n    yield defer.gatherResults([table_write(conn, table) for table in tables])\r\n\r\n    # Cancel the feeds and wait for them to exit\r\n    cancel.addErrback(lambda err: None)\r\n    cancel.cancel()\r\n    yield defer.DeferredList(feeds)\r\n\r\nyield notice_changes(conn, 'a', 'b')\r\n\r\n# Output\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 0}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 0}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 1}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 1}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 2}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 2}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 3}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 3}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 4}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 4}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 5}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 5}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 6}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 6}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 7}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 7}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 8}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 8}}\r\nSeen on table a: {u'old_val': None, u'new_val': {u'id': 9}}\r\nSeen on table b: {u'old_val': None, u'new_val': {u'id': 9}}\r\n```\r\n\r\nHere, we can listen for changes on multiple tables at once.  We simultaneously write into the tables, and observe our writes appear in the changefeeds.  We then cancel the changefeeds after we've written 10 items into each of the tables."
  , issueCommentId = 142169993
  }